{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7505d0d-3b3b-47c8-91a6-99e53514948c",
   "metadata": {},
   "source": [
    "## Read in necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a009ebf4-4dbb-4b4f-9427-8d254e0da06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirar\\anaconda3\\envs\\stan\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cmdstanpy as csp\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# for the loss functions\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9948e820-7c5a-4fe7-bc12-9fed734b28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(\"data_mags_5000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c5c6d8-deff-493a-8d2c-25774babf41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['template_id', 'median_z', 'mean_z', 'minchi2', 'mode_z', 'z_sigma68',\n",
       "       'z_sigma', 'z_mc', 'concentration_i', 'concentration_cal_i',\n",
       "       'asymmetry_i', 'clumpiness_i', 'gini_i', 'm20_i', 'mag_sersic_i',\n",
       "       'mag_cal_i', 're_sersic_i', 're_cal_i', 'n_sersic_i', 'n_sersic_cal_i',\n",
       "       'ellipticity_sersic_i', 'ellipticity_sersic_cal_i'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48c2f1-9b68-4ccf-8aec-0b9272eadd6f",
   "metadata": {},
   "source": [
    "Read in all relevant data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c627d9-bd98-45b4-9a40-352e1b0e0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template data\n",
    "group_id = data_all[\"template_id\"] + 1 # + 1 since python and stan use different indices\n",
    "\n",
    "# galaxy properties\n",
    "mag_sersic = data_all[\"mag_sersic_i\"]\n",
    "m20 = data_all['m20_i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cb8af9-2c86-42dd-9bde-9f758d385a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy way to change the data to run on ONLY CHANGE IT HERE\n",
    "x_data = mag_sersic\n",
    "y_data = m20\n",
    "\n",
    "# change labels for plots and accessing from dataframes\n",
    "# NOTE: string must be the same as a column from data_all in order to access the dataframe later\n",
    "x_label = \"mag_sersic_i\"\n",
    "y_label = \"m20_i\"\n",
    "\n",
    "# name the folder in the repo to save plots in. folder must exist already\n",
    "folder_name = \"saved-plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9378eb85-f914-4f51-8fa1-ec9fd05f4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other prior information needed for the model\n",
    "N = data_all.shape[0] # total number of objects\n",
    "\n",
    "num_templates = len(np.unique(group_id))\n",
    "\n",
    "a1 = 1\n",
    "b1 = 1\n",
    "a2 = 1\n",
    "b2 = 1\n",
    "nu = 3\n",
    "lambda_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e14acd-576a-4732-bb9b-ab4022f9f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data as input for the model into a single variable\n",
    "data = {'N': N, \n",
    "        'J': num_templates,\n",
    "        'm': np.max(group_id), \n",
    "        'y_data': y_data,\n",
    "        'x_data': x_data,\n",
    "        'group_id': group_id,\n",
    "        'a1': a1,\n",
    "        'b1': b1,\n",
    "        'a2': a2,\n",
    "        'b2': b2,\n",
    "        'nu': nu,\n",
    "        'lambda': lambda_var,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e204f-0366-44e8-a146-520e179fcf2a",
   "metadata": {},
   "source": [
    "### Define some extra loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6a0aaa-ae37-40f7-a505-411728f64f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define additional loss function methods\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792356d9-371e-4773-baac-a7843e445d07",
   "metadata": {},
   "source": [
    "## Run the three models for total pooling, no pooling, and partial pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093d2f1-6c7e-402a-8e4d-12cf0ec3e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_model = csp.CmdStanModel(stan_file = 'total-pooling.stan')\n",
    "total_sample = total_model.sample(data = data, seed = 1, chains = 1,\n",
    "                      iter_sampling = 1000, iter_warmup = 1000,\n",
    "                      show_progress = False, show_console = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2964974-545f-412f-a58f-c3c4fad908a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_model = csp.CmdStanModel(stan_file = 'no-pooling.stan')\n",
    "none_sample = none_model.sample(data = data, seed = 1, chains = 1,\n",
    "                      iter_sampling = 1000, iter_warmup = 1000,\n",
    "                      show_progress = False, show_console = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58acb3-86f4-4daa-8781-d1de0bb34a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_model = csp.CmdStanModel(stan_file = 'hierarchical-regression.stan')\n",
    "hier_sample = hier_model.sample(data = data, seed = 1, chains = 1,\n",
    "                      iter_sampling = 1000, iter_warmup = 1000,\n",
    "                      show_progress = False, show_console = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966aa72-ebb4-4e81-a80d-86f0d010c990",
   "metadata": {},
   "source": [
    "## Plotting by template type\n",
    "Group raw data by template ID and assign a color.\n",
    "\n",
    "Make a line collection of all alphas and betas from each template group. Add in alpha_bar and beta_bar for a global linear fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576b9f1-a3aa-4cad-9468-252427497951",
   "metadata": {},
   "source": [
    "### Total pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41576f1-bd85-438c-ada4-cd331964f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_group = np.array([np.mean(alpha_template) for alpha_template in total_sample.stan_variable(\"alpha\").transpose()])\n",
    "beta_group = np.array([np.mean(beta_template) for beta_template in total_sample.stan_variable(\"beta\").transpose()])\n",
    "color_map = np.arange(0, data_all[\"template_id\"].max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078c5e3-2e0e-473f-8db1-54b08fa31f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the global slope and intercept\n",
    "alpha_bar = np.mean(total_sample.stan_variable('alpha_bar'))\n",
    "beta_bar = np.mean(total_sample.stan_variable('beta_bar'))\n",
    "print(alpha_bar, beta_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00c1e5-4d40-49e5-b153-83c40b75ae36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs = np.arange(np.min(x_data), np.max(x_data), np.max(x_data)/1000)\n",
    "segs = [] # for collection of lines to plot\n",
    "masked_segs = [] # generate list of linear fits that pass the loss functions\n",
    "masked_alphas = [] # list of alphas that pass loss funtions\n",
    "masked_betas = [] # list of betas that pass loss functions\n",
    "masked_x_data = []\n",
    "masked_y_data = []\n",
    "masked_group_id = []\n",
    "\n",
    "for template_id in range(len(alpha_group)):\n",
    "    subset = data_all[data_all['template_id']==template_id]\n",
    "    \n",
    "    data = alpha_group[template_id] + beta_group[template_id]*xs\n",
    "    \n",
    "    segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "\n",
    "    if len(subset) < 10:\n",
    "        continue\n",
    "\n",
    "    predicted = alpha_group[template_id] + beta_group[template_id] * subset[x_label]\n",
    "    \n",
    "    # calculate loss functions\n",
    "    mse_val = mean_squared_error(subset[y_label], predicted)\n",
    "    r2_val = r2_score(subset[y_label], predicted)\n",
    "\n",
    "    if (mse_val < 0.7) and (r2_val > 0.25):\n",
    "        masked_segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "        masked_alphas.append(alpha_group[template_id])\n",
    "        masked_betas.append(beta_group[template_id])\n",
    "        masked_x_data.extend(subset[x_label])\n",
    "        masked_y_data.extend(subset[y_label])\n",
    "        masked_group_id.extend(np.full(len(subset[x_label]), template_id))\n",
    "\n",
    "# append the global linear fit as a single line, with all templates\n",
    "global_seg = []\n",
    "global_data = alpha_bar + beta_bar*xs\n",
    "global_seg.append(((xs[0], global_data[0]), (xs[-1], global_data[-1])))\n",
    "\n",
    "# append the global linear fit as a single line, with only good templates\n",
    "masked_global_seg = []\n",
    "masked_global_data = np.mean(masked_alphas) + np.mean(masked_betas)*xs\n",
    "masked_global_seg.append(((xs[0], masked_global_data[0]), (xs[-1], masked_global_data[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b41e7-1305-4f7a-94bd-48ba9a96f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all templates\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(x_data), np.max(x_data))    \n",
    "ax.set_ylim(np.min(y_data), np.max(y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear Total Pooling Model across all Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(x_data, y_data, c=group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_all_total_pool.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85ab2b-06ed-40ee-9842-9a8fd1e9a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot templates that pass the loss functions\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(masked_segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(masked_global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(masked_x_data), np.max(masked_x_data))    \n",
    "ax.set_ylim(np.min(masked_y_data), np.max(masked_y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear Total Pooling Model across masked Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(masked_x_data, masked_y_data, c=masked_group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_mask_total_pool.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb883133-a1b8-4c66-ac12-d1cfc2713334",
   "metadata": {},
   "source": [
    "### No pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694247f-7406-4de8-b318-5e9f959223bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_group = np.array([np.mean(alpha_template) for alpha_template in none_sample.stan_variable(\"alpha\").transpose()])\n",
    "beta_group = np.array([np.mean(beta_template) for beta_template in none_sample.stan_variable(\"beta\").transpose()])\n",
    "color_map = np.arange(0, data_all[\"template_id\"].max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984b1c8-5ef3-4acd-bef3-fbbf04257a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the global slope and intercept\n",
    "alpha_bar = np.mean(none_sample.stan_variable('alpha_bar'))\n",
    "beta_bar = np.mean(none_sample.stan_variable('beta_bar'))\n",
    "print(alpha_bar, beta_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b896d-d34b-486e-bbe3-dcaf1fe0ebb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs = np.arange(np.min(x_data), np.max(x_data), np.max(x_data)/1000)\n",
    "segs = [] # for collection of lines to plot\n",
    "masked_segs = [] # generate list of linear fits that pass the loss functions\n",
    "masked_alphas = [] # list of alphas that pass loss funtions\n",
    "masked_betas = [] # list of betas that pass loss functions\n",
    "masked_x_data = []\n",
    "masked_y_data = []\n",
    "masked_group_id = []\n",
    "\n",
    "for template_id in range(len(alpha_group)):\n",
    "    subset = data_all[data_all['template_id']==template_id]\n",
    "    \n",
    "    data = alpha_group[template_id] + beta_group[template_id]*xs\n",
    "    \n",
    "    segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "\n",
    "    if len(subset) < 10:\n",
    "        continue\n",
    "\n",
    "    predicted = alpha_group[template_id] + beta_group[template_id] * subset[x_label]\n",
    "    \n",
    "    # calculate loss functions\n",
    "    mse_val = mean_squared_error(subset[y_label], predicted)\n",
    "    r2_val = r2_score(subset[y_label], predicted)\n",
    "\n",
    "    if (mse_val < 0.7) and (r2_val > 0.25):\n",
    "        masked_segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "        masked_alphas.append(alpha_group[template_id])\n",
    "        masked_betas.append(beta_group[template_id])\n",
    "        masked_x_data.extend(subset[x_label])\n",
    "        masked_y_data.extend(subset[y_label])\n",
    "        masked_group_id.extend(np.full(len(subset[x_label]), template_id))\n",
    "\n",
    "# append the global linear fit as a single line, with all templates\n",
    "global_seg = []\n",
    "global_data = alpha_bar + beta_bar*xs\n",
    "global_seg.append(((xs[0], global_data[0]), (xs[-1], global_data[-1])))\n",
    "\n",
    "# append the global linear fit as a single line, with only good templates\n",
    "masked_global_seg = []\n",
    "masked_global_data = np.mean(masked_alphas) + np.mean(masked_betas)*xs\n",
    "masked_global_seg.append(((xs[0], masked_global_data[0]), (xs[-1], masked_global_data[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7715a6-f836-4332-8d3c-8a09e3ffd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all templates\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(x_data), np.max(x_data))    \n",
    "ax.set_ylim(np.min(y_data), np.max(y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear No Pooling Model across all Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(x_data, y_data, c=group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_all_no_pool.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924695b-8d42-4e52-bb47-54dc172a0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot templates that pass the loss functions\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(masked_segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(masked_global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(masked_x_data), np.max(masked_x_data))    \n",
    "ax.set_ylim(np.min(masked_y_data), np.max(masked_y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear No Pooling Model across masked Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(masked_x_data, masked_y_data, c=masked_group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_mask_no_pool.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b0829-316f-4a16-8ccd-697d5e983540",
   "metadata": {},
   "source": [
    "### Partial Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89f266-01fc-4392-9afb-8cfecff63a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_group = np.array([np.mean(alpha_template) for alpha_template in hier_sample.stan_variable(\"alpha\").transpose()])\n",
    "beta_group = np.array([np.mean(beta_template) for beta_template in hier_sample.stan_variable(\"beta\").transpose()])\n",
    "color_map = np.arange(0, data_all[\"template_id\"].max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472d2a7-646c-4230-b698-3dfcf421fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the global slope and intercept\n",
    "alpha_bar = np.mean(hier_sample.stan_variable('alpha_bar'))\n",
    "beta_bar = np.mean(hier_sample.stan_variable('beta_bar'))\n",
    "print(alpha_bar, beta_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122d3d7-ea8d-4152-895c-713b8294ca1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs = np.arange(np.min(x_data), np.max(x_data), np.max(x_data)/1000)\n",
    "segs = [] # for collection of lines to plot\n",
    "masked_segs = [] # generate list of linear fits that pass the loss functions\n",
    "masked_alphas = [] # list of alphas that pass loss funtions\n",
    "masked_betas = [] # list of betas that pass loss functions\n",
    "masked_x_data = []\n",
    "masked_y_data = []\n",
    "masked_group_id = []\n",
    "\n",
    "for template_id in range(len(alpha_group)):\n",
    "    subset = data_all[data_all['template_id']==template_id]\n",
    "    \n",
    "    data = alpha_group[template_id] + beta_group[template_id]*xs\n",
    "    \n",
    "    segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "\n",
    "    if len(subset) < 10:\n",
    "        continue\n",
    "\n",
    "    predicted = alpha_group[template_id] + beta_group[template_id] * subset[x_label]\n",
    "    \n",
    "    # calculate loss functions\n",
    "    mse_val = mean_squared_error(subset[y_label], predicted)\n",
    "    r2_val = r2_score(subset[y_label], predicted)\n",
    "\n",
    "    if (mse_val < 0.7) and (r2_val > 0.25):\n",
    "        masked_segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "        masked_alphas.append(alpha_group[template_id])\n",
    "        masked_betas.append(beta_group[template_id])\n",
    "        masked_x_data.extend(subset[x_label])\n",
    "        masked_y_data.extend(subset[y_label])\n",
    "        masked_group_id.extend(np.full(len(subset[x_label]), template_id))\n",
    "\n",
    "# append the global linear fit as a single line, with all templates\n",
    "global_seg = []\n",
    "global_data = alpha_bar + beta_bar*xs\n",
    "global_seg.append(((xs[0], global_data[0]), (xs[-1], global_data[-1])))\n",
    "\n",
    "# append the global linear fit as a single line, with only good templates\n",
    "masked_global_seg = []\n",
    "masked_global_data = np.mean(masked_alphas) + np.mean(masked_betas)*xs\n",
    "masked_global_seg.append(((xs[0], masked_global_data[0]), (xs[-1], masked_global_data[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5c854-3e39-46fc-add4-52e545a8646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all templates\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(x_data), np.max(x_data))    \n",
    "ax.set_ylim(np.min(y_data), np.max(y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear Hierarchical Model across all Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(x_data, y_data, c=group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_all_partial_pool.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9570f-25a6-4700-a9c7-240c754888e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot templates that pass the loss functions\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(masked_segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(masked_global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(masked_x_data), np.max(masked_x_data))    \n",
    "ax.set_ylim(np.min(masked_y_data), np.max(masked_y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear Hierarchical Model across masked Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(masked_x_data, masked_y_data, c=masked_group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_mask_partial_pool.png\", dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
