{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa2f788-f289-4de6-b8e7-fe2b52d3f19d",
   "metadata": {},
   "source": [
    "## Initial hierarchical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7aaf13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install cmdstanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba87d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install -e git+https://github.com/stan-dev/cmdstanpy@develop#egg=cmdstanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05aacfe0-2c7f-4995-af6d-555cdb99a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirar\\anaconda3\\envs\\stan\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cmdstanpy as csp\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# for the loss functions\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90aeaa33-a4a1-4f46-ae3f-ee35d3d7a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(\"data_mags_5000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39601162-23a7-4915-887c-e3df79438886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['template_id', 'median_z', 'mean_z', 'minchi2', 'mode_z', 'z_sigma68',\n",
       "       'z_sigma', 'z_mc', 'concentration_i', 'concentration_cal_i',\n",
       "       'asymmetry_i', 'clumpiness_i', 'gini_i', 'm20_i', 'mag_sersic_i',\n",
       "       'mag_cal_i', 're_sersic_i', 're_cal_i', 'n_sersic_i', 'n_sersic_cal_i',\n",
       "       'ellipticity_sersic_i', 'ellipticity_sersic_cal_i'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46d02e-7124-4fef-bf26-7da0c9680092",
   "metadata": {},
   "source": [
    "Read in all relevant data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d15ebc-ed9d-4482-87ab-20a549c74e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template data\n",
    "group_id = data_all[\"template_id\"] + 1 # + 1 since python and stan use different indices\n",
    "\n",
    "# for redshift (less relevant)\n",
    "median_z = data_all[\"median_z\"]\n",
    "z_sigma68 = data_all[\"z_sigma68\"]\n",
    "z_sigma = data_all[\"z_sigma\"]\n",
    "min_chi_z = data_all[\"minchi2\"] # chi^2 of best fit template type\n",
    "\n",
    "# galaxy properties\n",
    "mag_sersic = data_all[\"mag_sersic_i\"]\n",
    "mag_cal = data_all[\"mag_cal_i\"]\n",
    "concentration = data_all['concentration_i']\n",
    "asymmetry = data_all['asymmetry_i']\n",
    "concentration = data_all['concentration_i']\n",
    "clumpiness = data_all['clumpiness_i']\n",
    "gini = data_all['gini_i']\n",
    "m20 = data_all['m20_i']\n",
    "re_sersic = data_all['re_sersic_i']\n",
    "concentration = data_all['concentration_i']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ef862-ece5-47cb-9e16-4f0ae5044e4b",
   "metadata": {},
   "source": [
    "Run the following relationships in the model (y vs x):\n",
    "\n",
    "- `m20_i` vs magnitude\n",
    "    - **Use as test dataset for determining priors, data cuts, and pooling amounts**\n",
    "- Concentration vs magnitude\n",
    "- Asymmetry vs magnitude\n",
    "- Clumpiness vs magnitude\n",
    "- `gini_i` vs magnitude\n",
    "- Concentration vs `re_sersic_i`\n",
    "- `gini_i` vs `m20_i` (? from paper)\n",
    "- Magnitude vs z (unlikely but worth a shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba13f9a-1012-4965-a8c5-1fab44073b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy way to change the data to run on ONLY CHANGE IT HERE\n",
    "x_data = mag_sersic\n",
    "y_data = m20\n",
    "\n",
    "# change labels for plots and accessing from dataframes\n",
    "# NOTE: string must be the same as a column from data_all in order to access the dataframe later\n",
    "x_label = \"mag_sersic_i\"\n",
    "y_label = \"m20_i\"\n",
    "\n",
    "# name the folder in the repo to save plots in. folder must exist already\n",
    "folder_name = \"saved-plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0c39f9-80ea-4d13-befc-1ccb335bcb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other prior information needed for the model\n",
    "N = data_all.shape[0] # total number of objects\n",
    "\n",
    "num_templates = len(np.unique(group_id))\n",
    "\n",
    "a1 = 1\n",
    "b1 = 1\n",
    "a2 = 1\n",
    "b2 = 1\n",
    "nu = 3\n",
    "lambda_var = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88555fd4-b976-40da-b4de-6a1a526ff2d7",
   "metadata": {},
   "source": [
    "Not all templates may necessarily be represented in the choosen data set. Due to this, the number of templates may not necessarilly be as large as the maximum group_id value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337c09c4-5036-42ca-9409-f19ab9372589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data as input for the model into a single variable\n",
    "data = {'N': N, \n",
    "        'J': num_templates,\n",
    "        'm': np.max(group_id), \n",
    "        'y_data': y_data,\n",
    "        'x_data': x_data,\n",
    "        'group_id': group_id,\n",
    "        'a1': a1,\n",
    "        'b1': b1,\n",
    "        'a2': a2,\n",
    "        'b2': b2,\n",
    "        'nu': nu,\n",
    "        'lambda': lambda_var,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a5e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from cmdstanpy import install_cmdstan\n",
    "#install_cmdstan(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad397db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:04:35 - cmdstanpy - INFO - CmdStan start processing\n",
      "10:04:35 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    }
   ],
   "source": [
    "model = csp.CmdStanModel(stan_file = 'hierarchical-regression.stan')\n",
    "sample = model.sample(data = data, seed = 1, chains = 1,\n",
    "                      iter_sampling = 1000, iter_warmup = 1000,\n",
    "                      show_progress = False, show_console = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ae3fd-24df-4812-8c74-11a942b407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to save a model\n",
    "# sample.save_csvfiles(\"second-run-sigma68/model-data-50000-prior1\")\n",
    "\n",
    "# how to read a saved file\n",
    "#sample = csp.from_csv(\"model-data-cut-5000/hierarchical-regression-20240422121707.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20a87d-cbe9-4897-b3ad-a4c9c18bfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = sample.stan_variable(\"alpha\")\n",
    "beta_list = sample.stan_variable(\"beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4e7d3-68be-4114-82b7-3ead3450db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alpha_list.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4111f9f5-8505-41cd-a777-9107373fba75",
   "metadata": {},
   "source": [
    "# plot all realizations of the generated lines from the model for a specific template type\n",
    "# ignore this plot for now\n",
    "\n",
    "group_index = 41\n",
    "\n",
    "zs = np.arange(0, np.max(x_data), np.max(x_data)/1000)\n",
    "segs = []\n",
    "for i in range(alpha_list.shape[0]):\n",
    "    data = alpha_list[i][group_index] + beta_list[i][group_index]*zs\n",
    "    segs.append(((zs[0], data[0]), (zs[-1], data[-1])))\n",
    "\n",
    "# get first group of data\n",
    "group1_y = np.array(y_data)[np.where(group_id==group_index)]\n",
    "group1_x = np.array(x_data)[np.where(group_id==group_index)]\n",
    "\n",
    "# plot the group data\n",
    "\n",
    "ln_coll = matplotlib.collections.LineCollection(segs, alpha=0.1)\n",
    "ax = plt.gca()\n",
    "ax2 = plt.scatter(group1_x, group1_y, color='orange')\n",
    "ax.add_collection(ln_coll)\n",
    "ax.set_xlim(np.min(x_data), np.max(x_data))    \n",
    "ax.set_ylim(np.min(y_data), np.max(y_data))\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ca499-01a5-46e9-85d1-abff35d8c300",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a25f3c-1571-4be5-9f52-090cbf2c21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define additional loss function methods\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2071026-2b79-495a-8fb6-3773920d0647",
   "metadata": {},
   "source": [
    "## Plotting by template type\n",
    "Group raw data by template ID and assign a color.\n",
    "\n",
    "Make a line collection of all alphas and betas from each template group. Add in alpha_bar and beta_bar for a global linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72fc39-ce63-434c-9174-d048097efb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_group = np.array([np.mean(alpha_template) for alpha_template in sample.stan_variable(\"alpha\").transpose()])\n",
    "beta_group = np.array([np.mean(beta_template) for beta_template in sample.stan_variable(\"beta\").transpose()])\n",
    "color_map = np.arange(0, data_all[\"template_id\"].max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e634a-e3dd-4c4f-bd19-49904a643fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the global slope and intercept\n",
    "alpha_bar = np.mean(sample.stan_variable('alpha_bar'))\n",
    "beta_bar = np.mean(sample.stan_variable('beta_bar'))\n",
    "print(alpha_bar, beta_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061af0be-7445-4a94-a279-af00ef64cdb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs = np.arange(np.min(x_data), np.max(x_data), np.max(x_data)/1000)\n",
    "segs = [] # for collection of lines to plot\n",
    "masked_segs = [] # generate list of linear fits that pass the loss functions\n",
    "masked_alphas = [] # list of alphas that pass loss funtions\n",
    "masked_betas = [] # list of betas that pass loss functions\n",
    "masked_x_data = []\n",
    "masked_y_data = []\n",
    "masked_group_id = []\n",
    "\n",
    "for template_id in range(len(alpha_group)):\n",
    "    subset = data_all[data_all['template_id']==template_id]\n",
    "    \n",
    "    data = alpha_group[template_id] + beta_group[template_id]*xs\n",
    "    \n",
    "    segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "\n",
    "    if len(subset) < 10:\n",
    "        continue\n",
    "\n",
    "    predicted = alpha_group[template_id] + beta_group[template_id] * subset[x_label]\n",
    "    \n",
    "    # calculate loss functions\n",
    "    mse_val = mean_squared_error(subset[y_label], predicted)\n",
    "    r2_val = r2_score(subset[y_label], predicted)\n",
    "\n",
    "    if (mse_val < 0.7) and (r2_val > 0.25):\n",
    "        masked_segs.append(((xs[0], data[0]), (xs[-1], data[-1])))\n",
    "        masked_alphas.append(alpha_group[template_id])\n",
    "        masked_betas.append(beta_group[template_id])\n",
    "        masked_x_data.extend(subset[x_label])\n",
    "        masked_y_data.extend(subset[y_label])\n",
    "        masked_group_id.extend(np.full(len(subset[x_label]), template_id))\n",
    "\n",
    "# append the global linear fit as a single line, with all templates\n",
    "global_seg = []\n",
    "global_data = alpha_bar + beta_bar*xs\n",
    "global_seg.append(((xs[0], global_data[0]), (xs[-1], global_data[-1])))\n",
    "\n",
    "# append the global linear fit as a single line, with only good templates\n",
    "masked_global_seg = []\n",
    "masked_global_data = np.mean(masked_alphas) + np.mean(masked_betas)*xs\n",
    "masked_global_seg.append(((xs[0], masked_global_data[0]), (xs[-1], masked_global_data[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48871f83-1a33-4640-b330-063414f19ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all templates\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(x_data), np.max(x_data))    \n",
    "ax.set_ylim(np.min(y_data), np.max(y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear Hierarchical Model across all Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(x_data, y_data, c=group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_all_data_plot.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d258c-f982-42d6-9a7a-c2e09e9af000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot templates that pass the loss functions\n",
    "fig, ax = plt.subplots()\n",
    "ln_coll = matplotlib.collections.LineCollection(masked_segs, array=color_map, alpha=0.8, linewidths=1.5)\n",
    "global_ln_coll = matplotlib.collections.LineCollection(masked_global_seg, color='red', alpha=0.9, linewidths=3)\n",
    "\n",
    "ax.set_xlim(np.min(masked_x_data), np.max(masked_x_data))    \n",
    "ax.set_ylim(np.min(masked_y_data), np.max(masked_y_data))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Linear Hierarchical Model across masked Template Types\")\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "ax.add_collection(global_ln_coll)\n",
    "ax.scatter(masked_x_data, masked_y_data, c=masked_group_id, alpha=0.8)\n",
    "\n",
    "template_color = fig.colorbar(ln_coll)\n",
    "template_color.set_label('Template ID')\n",
    "fig.savefig(f\"{folder_name}{y_label}_vs_{x_label}_mask_data_plot.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd133a0-d86c-42fd-b666-ebb1505df6f2",
   "metadata": {},
   "source": [
    "## Introducing magnitudes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f86dd59-3aa7-4309-afc1-108f2fcea4f4",
   "metadata": {},
   "source": [
    "mag_ratio = np.abs(mag_cal) / mag_sersic"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3a1717c-b3bf-460f-998f-5b49e9ed10a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "plt.scatter(mag_sersic, mag_ratio)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3659e213-5c53-408f-8419-d59bd83157af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "plt.scatter(concentration_i, mag_sersic)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9c631d0-4da1-4683-9841-df15924400f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "plt.scatter(clumpiness_i, mag_sersic)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f56d30a-11ec-418e-b092-59126366e53e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "plt.scatter(gini_i, mag_sersic)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "505db8f0-f5ae-40ce-8914-b4b1dee8b9e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "plt.scatter(m20_i, mag_sersic)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86bf6146-888c-4b70-8b52-14c396026bb2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "plt.scatter(concentration_i, re_sersic_i)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee68ed8b-7540-4d23-b60f-dd681f8fe3d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "plt.scatter(mag_sersic, median_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1ef39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
